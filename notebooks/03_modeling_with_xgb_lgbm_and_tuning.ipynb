{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dac43bbc",
   "metadata": {},
   "source": [
    "# 03 – Modeling: Predicting High-Growth YouTube Videos\n",
    "\n",
    "This notebook trains and evaluates machine learning models to predict whether a\n",
    "YouTube video will become a **high-growth video** based on its early performance\n",
    "metrics and Google Trends signals.\n",
    "\n",
    "We use the final feature set produced in `02_feature_engineering.ipynb`, where\n",
    "YouTube metadata has been merged with category-level Google Trends scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc5465",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03_modeling.ipynb\n",
    "# High-growth video prediction using YouTube and Google Trends features\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    RocCurveDisplay,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "print(\"Modeling notebook ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58798530",
   "metadata": {},
   "source": [
    "## 2. Load Features With Google Trends\n",
    "\n",
    "We load the processed feature set `features_with_trends.csv` from the\n",
    "`../data/processed/` directory. This dataset already contains:\n",
    "\n",
    "- YouTube video metrics (views, likes, comments, etc.)\n",
    "- Engineered ratios (like/view, comment/view)\n",
    "- Time-based features (publish hour, etc.)\n",
    "- Category-level Google Trends scores and rolling averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9fb1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the final feature set (merged with Google Trends)\n",
    "features_path = \"../data/processed/features_with_trends.csv\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    features_path,\n",
    "    parse_dates=[\"trending_date\", \"publish_date\"],\n",
    ")\n",
    "\n",
    "print(\"Features shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759b6f5f",
   "metadata": {},
   "source": [
    "## 3. Feature Selection and Missing Value Handling\n",
    "\n",
    "We define the list of features used for modeling. Note that we intentionally\n",
    "exclude future-dependent variables such as `view_growth` or `growth_rate` from\n",
    "the input features to avoid data leakage.\n",
    "\n",
    "Since Google Trends data is merged with a left join, some rows may not have a\n",
    "trend value. To ensure the models can be trained, we impute missing numeric\n",
    "values with the **median** of each feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7eb004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect distribution of the target variable\n",
    "print(\"High-growth label distribution (fraction):\")\n",
    "print(df[\"high_growth\"].value_counts(normalize=True))\n",
    "\n",
    "# Features to be used in the models\n",
    "feature_cols = [\n",
    "    \"views\",\n",
    "    \"likes\",\n",
    "    \"dislikes\",\n",
    "    \"comment_count\",\n",
    "    \"like_view_ratio\",\n",
    "    \"comment_view_ratio\",\n",
    "    \"publish_hour\",\n",
    "    \"category_id\",\n",
    "    \"trend_score\",\n",
    "    \"trend_score_3d_mean\",\n",
    "    \"trend_score_7d_mean\",\n",
    "]\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nNumber of NaNs per feature before imputation:\")\n",
    "print(df[feature_cols].isna().sum())\n",
    "\n",
    "# Simple and robust imputation strategy:\n",
    "# - numeric features -> median\n",
    "# - non-numeric features (if any) -> -1 as a dummy category\n",
    "for col in feature_cols:\n",
    "    if df[col].dtype.kind in \"iuf\":  # int/unsigned/float\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    else:\n",
    "        df[col] = df[col].fillna(-1)\n",
    "\n",
    "print(\"\\nNumber of NaNs per feature after imputation:\")\n",
    "print(df[feature_cols].isna().sum())\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[\"high_growth\"].astype(int)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0763c7aa",
   "metadata": {},
   "source": [
    "## 4. Time-Based Train / Validation / Test Split\n",
    "\n",
    "Instead of using a random split, we respect the temporal nature of the data:\n",
    "\n",
    "- The dataset is sorted by `trending_date`.\n",
    "- The oldest **60%** of the rows are used for **training**.\n",
    "- The next **20%** are reserved for **validation** (not explicitly tuned here,\n",
    "  but could be used for hyperparameter search).\n",
    "- The most recent **20%** are used for **testing**.\n",
    "\n",
    "This setup mimics a realistic scenario: we train models on past data and\n",
    "evaluate them on future videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based train/validation/test split\n",
    "df_sorted = df.sort_values(\"trending_date\").reset_index(drop=True)\n",
    "\n",
    "n = len(df_sorted)\n",
    "train_end = int(n * 0.6)\n",
    "val_end = int(n * 0.8)\n",
    "\n",
    "train = df_sorted.iloc[:train_end]\n",
    "val = df_sorted.iloc[train_end:val_end]\n",
    "test = df_sorted.iloc[val_end:]\n",
    "\n",
    "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")\n",
    "\n",
    "X_train = train[feature_cols]\n",
    "y_train = train[\"high_growth\"].astype(int)\n",
    "\n",
    "X_val = val[feature_cols]\n",
    "y_val = val[\"high_growth\"].astype(int)\n",
    "\n",
    "X_test = test[feature_cols]\n",
    "y_test = test[\"high_growth\"].astype(int)\n",
    "\n",
    "print(\"\\nLabel distribution (train, val, test):\")\n",
    "print(y_train.value_counts(normalize=True), \n",
    "      y_val.value_counts(normalize=True), \n",
    "      y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d4e805",
   "metadata": {},
   "source": [
    "## 5. Models and Evaluation Metrics\n",
    "\n",
    "We evaluate several supervised classification models:\n",
    "\n",
    "1. **Logistic Regression** – a simple linear baseline.\n",
    "2. **Random Forest** – a non-linear ensemble model.\n",
    "3. **XGBoost** – a gradient boosting model, strong on tabular data.\n",
    "4. **LightGBM** – a fast gradient boosting model optimized for large and sparse features.\n",
    "\n",
    "For each model we report:\n",
    "\n",
    "- **Accuracy**\n",
    "- **F1-score**\n",
    "- **ROC-AUC**\n",
    "- A full classification report (precision, recall, F1 per class).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adde4517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(model, X_tr, y_tr, X_te, y_te, name=\"Model\"):\n",
    "    \"\"\"Prints basic evaluation metrics and returns them in a dictionary.\"\"\"\n",
    "    y_pred = model.predict(X_te)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_te)[:, 1]\n",
    "        roc = roc_auc_score(y_te, y_proba)\n",
    "    else:\n",
    "        y_scores = model.decision_function(X_te)\n",
    "        roc = roc_auc_score(y_te, y_scores)\n",
    "\n",
    "    acc = accuracy_score(y_te, y_pred)\n",
    "    f1 = f1_score(y_te, y_pred)\n",
    "\n",
    "    print(f\"\\n==== {name} ====\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"F1-score:\", f1)\n",
    "    print(\"ROC-AUC:\", roc)\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_te, y_pred))\n",
    "\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"roc_auc\": roc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f5a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model: Logistic Regression\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "metrics_lr = evaluate_classifier(\n",
    "    log_reg, X_train, y_train, X_test, y_test, name=\"Logistic Regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e403bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-linear model: Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "metrics_rf = evaluate_classifier(\n",
    "    rf, X_train, y_train, X_test, y_test, name=\"Random Forest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c9ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Classifier\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "metrics_xgb = evaluate_classifier(\n",
    "    xgb, X_train, y_train, X_test, y_test, name=\"XGBoost\"\n",
    ")\n",
    "\n",
    "metrics_xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20df5d75",
   "metadata": {},
   "source": [
    "### 5.1 LightGBM Classifier\n",
    "\n",
    "As another gradient boosting approach, we train a **LightGBM** classifier on the same\n",
    "feature set. LightGBM is designed for speed and can handle large, sparse feature\n",
    "spaces efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80057cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting model: LightGBM\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective=\"binary\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "metrics_lgbm = evaluate_classifier(\n",
    "    lgbm, X_train, y_train, X_test, y_test, name=\"LightGBM\"\n",
    ")\n",
    "\n",
    "metrics_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e777913b",
   "metadata": {},
   "source": [
    "### 5.2 ROC Curves for All Models\n",
    "\n",
    "To compare discriminative performance across models, we plot ROC curves on the\n",
    "same test set for:\n",
    "\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "\n",
    "This allows us to visually inspect which model better separates high-growth from\n",
    "non–high-growth videos at different classification thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d13a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves for all models on the test set\n",
    "models_for_roc = [\n",
    "    (\"Logistic Regression\", log_reg),\n",
    "    (\"Random Forest\", rf),\n",
    "    (\"XGBoost\", xgb),\n",
    "    (\"LightGBM\", lgbm),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "for name, model in models_for_roc:\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_scores = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_scores = model.decision_function(X_test)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "    auc = roc_auc_score(y_test, y_scores)\n",
    "    ax.plot(fpr, tpr, label=f\"{name} (AUC = {auc:.3f})\")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\", color=\"grey\", label=\"Chance\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.set_title(\"ROC Curves – Test Set\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb22bd8",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrices and Feature Importances (Tree-Based Models)\n",
    "\n",
    "Tree-based ensemble models such as Random Forest, XGBoost, and LightGBM\n",
    "often perform better when there are non-linear relationships and interactions\n",
    "between features.\n",
    "\n",
    "In this section we inspect:\n",
    "\n",
    "- The confusion matrices on the test set.\n",
    "- Feature importances estimated by each tree-based model.\n",
    "\n",
    "This helps us understand which signals (e.g., early views, engagement ratios,\n",
    "Google Trends scores) contribute the most to predicting high-growth videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for tree-based models\n",
    "tree_models = [\n",
    "    (\"Random Forest\", rf),\n",
    "    (\"XGBoost\", xgb),\n",
    "    (\"LightGBM\", lgbm),\n",
    "]\n",
    "\n",
    "for name, model in tree_models:\n",
    "    cm = confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(f\"Confusion Matrix – {name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances for tree-based models\n",
    "tree_models = [\n",
    "    (\"Random Forest\", rf),\n",
    "    (\"XGBoost\", xgb),\n",
    "    (\"LightGBM\", lgbm),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(tree_models), figsize=(5 * len(tree_models), 4), sharey=True)\n",
    "\n",
    "for ax, (name, model) in zip(axes, tree_models):\n",
    "    importances = pd.Series(model.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "    importances.plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_title(name)\n",
    "    ax.set_ylabel(\"Importance\")\n",
    "    ax.tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "plt.suptitle(\"Feature Importances – Tree-Based Models\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d0f01",
   "metadata": {},
   "source": [
    "### 6.1 Optional: Hyperparameter Tuning for XGBoost\n",
    "\n",
    "As an optional step, we can perform a small hyperparameter search for XGBoost\n",
    "using `GridSearchCV`. The grid below contains 16 combinations (2×2×2×2), which\n",
    "is enough to see whether tuning materially improves ROC-AUC without taking too\n",
    "much time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small hyperparameter search for XGBoost (optional)\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"max_depth\": [4, 6],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "}\n",
    "\n",
    "xgb_base = XGBClassifier(\n",
    "    colsample_bytree=0.9,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV ROC-AUC:\", grid.best_score_)\n",
    "\n",
    "xgb_tuned = grid.best_estimator_\n",
    "\n",
    "metrics_xgb_tuned = evaluate_classifier(\n",
    "    xgb_tuned, X_train, y_train, X_test, y_test, name=\"XGBoost (tuned)\"\n",
    ")\n",
    "\n",
    "metrics_xgb_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b675c",
   "metadata": {},
   "source": [
    "## 7. Impact of Google Trends Features\n",
    "\n",
    "To quantify the added value of Google Trends, we compare two Random Forest models:\n",
    "\n",
    "- **RF WITHOUT Trends**: trained on YouTube features only  \n",
    "  (`views`, `likes`, `comment_view_ratio`, `publish_hour`, `category_id`, etc.).\n",
    "\n",
    "- **RF WITH Trends**: trained on the full feature set, including  \n",
    "  `trend_score`, `trend_score_3d_mean`, `trend_score_7d_mean`.\n",
    "\n",
    "By comparing their Accuracy, F1-score, and ROC-AUC on the same test set, we can\n",
    "assess whether Google Trends provides additional predictive power.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14787070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend-related columns\n",
    "trend_cols = [\"trend_score\", \"trend_score_3d_mean\", \"trend_score_7d_mean\"]\n",
    "\n",
    "base_features = [c for c in feature_cols if c not in trend_cols]\n",
    "trend_features = feature_cols  # all features\n",
    "\n",
    "\n",
    "def train_eval_rf(feature_list, name=\"\"):\n",
    "    X_train_f = train[feature_list]\n",
    "    X_test_f = test[feature_list]\n",
    "    y_train_f = train[\"high_growth\"].astype(int)\n",
    "    y_test_f = test[\"high_growth\"].astype(int)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    model.fit(X_train_f, y_train_f)\n",
    "\n",
    "    y_pred = model.predict(X_test_f)\n",
    "    y_proba = model.predict_proba(X_test_f)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test_f, y_pred)\n",
    "    f1 = f1_score(y_test_f, y_pred)\n",
    "    roc = roc_auc_score(y_test_f, y_proba)\n",
    "\n",
    "    print(f\"\\n==== {name} ====\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"F1:\", f1)\n",
    "    print(\"ROC-AUC:\", roc)\n",
    "\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"roc_auc\": roc}\n",
    "\n",
    "\n",
    "metrics_rf_no_trend = train_eval_rf(base_features, name=\"RF WITHOUT Trends\")\n",
    "metrics_rf_with_trend = train_eval_rf(trend_features, name=\"RF WITH Trends\")\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    {\n",
    "        \"model\": [\"RF_without_trends\", \"RF_with_trends\"],\n",
    "        \"accuracy\": [metrics_rf_no_trend[\"accuracy\"], metrics_rf_with_trend[\"accuracy\"]],\n",
    "        \"f1\": [metrics_rf_no_trend[\"f1\"], metrics_rf_with_trend[\"f1\"]],\n",
    "        \"roc_auc\": [metrics_rf_no_trend[\"roc_auc\"], metrics_rf_with_trend[\"roc_auc\"]],\n",
    "    }\n",
    ")\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40dad3",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "- The Random Forest model typically outperforms Logistic Regression on the test\n",
    "  set, suggesting non-linear relationships between features and the `high_growth`\n",
    "  label.\n",
    "- Adding Google Trends features often leads to an improvement in overall\n",
    "  performance (especially ROC-AUC and/or F1-score), indicating that external\n",
    "  trend signals carry useful information beyond YouTube-internal metrics.\n",
    "- The most important features usually include early views, engagement ratios\n",
    "  (like/view, comment/view), and category-level trend scores.\n",
    "- The final model can be exported locally as a `.pkl` file for deployment or\n",
    "  further analysis.\n",
    "\n",
    "> **Note:** Model artifacts (`.pkl` files) are intentionally not stored in the\n",
    "> GitHub repository to avoid large binary files. They can be regenerated by\n",
    "> rerunning this notebook, or stored in external storage if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4719dc1e",
   "metadata": {},
   "source": [
    "## 9. (Optional) Save the Trained Model Locally\n",
    "\n",
    "If you want to save the trained Random Forest model for later use (outside of\n",
    "this notebook), you can uncomment and run the following cell. This will create\n",
    "a `models/` directory (if it does not exist) and store the model as a `.pkl`\n",
    "file **on your local machine only**.\n",
    "\n",
    "Remember **not to commit or push** such large model files to GitHub; instead,\n",
    "add `models/` and `*.pkl` to your `.gitignore`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# import os\n",
    "\n",
    "# os.makedirs(\"../models\", exist_ok=True)\n",
    "# model_path = \"../models/final_rf_model.pkl\"\n",
    "# joblib.dump(rf, model_path)\n",
    "# print(f\"Random Forest model saved to: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
