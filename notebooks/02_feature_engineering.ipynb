{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 02_feature_engineering.ipynb\n",
    "    # Feature Engineering for US YouTube Trending Videos\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    print(\"Feature engineering notebook ready.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Load raw data\n",
    "    df = pd.read_csv(\"../data/raw/USvideos.csv\")\n",
    "\n",
    "    # Recreate ratios in case this notebook is run standalone\n",
    "    df[\"like_view_ratio\"] = df[\"likes\"] / (df[\"views\"] + 1e-6)\n",
    "    df[\"comment_view_ratio\"] = df[\"comment_count\"] / (df[\"views\"] + 1e-6)\n",
    "\n",
    "    df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Parse publish_time into datetime, date and hour components\n",
    "    df[\"publish_time\"] = pd.to_datetime(df[\"publish_time\"], errors=\"coerce\")\n",
    "    df[\"publish_date\"] = df[\"publish_time\"].dt.date\n",
    "    df[\"publish_hour\"] = df[\"publish_time\"].dt.hour\n",
    "\n",
    "    df[[\"publish_time\", \"publish_date\", \"publish_hour\"]].head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Fix trending_date format: original is 'YY.DD.MM', e.g. '17.14.11' meaning 2017-11-14\n",
    "    def fix_trending_date(x: str) -> str:\n",
    "        yy, dd, mm = x.split(\".\")\n",
    "        return f\"20{yy}-{mm}-{dd}\"\n",
    "\n",
    "    df[\"trending_date_fixed\"] = df[\"trending_date\"].apply(fix_trending_date)\n",
    "    df[\"trending_date\"] = pd.to_datetime(df[\"trending_date_fixed\"], errors=\"coerce\")\n",
    "    df = df.drop(columns=[\"trending_date_fixed\"])\n",
    "\n",
    "    df[[\"trending_date\"]].head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Sort by video_id and trending_date so that we can compute next-day views\n",
    "    df = df.sort_values(by=[\"video_id\", \"trending_date\"])\n",
    "    df[[\"video_id\", \"trending_date\", \"views\"]].head(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Compute next-day view count per video\n",
    "    df[\"views_next_day\"] = df.groupby(\"video_id\")[\"views\"].shift(-1)\n",
    "\n",
    "    df[[\"video_id\", \"trending_date\", \"views\", \"views_next_day\"]].head(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Compute absolute and relative growth\n",
    "    df[\"view_growth\"] = df[\"views_next_day\"] - df[\"views\"]\n",
    "    df[\"growth_rate\"] = df[\"view_growth\"] / (df[\"views\"] + 1e-6)\n",
    "\n",
    "    df[[\"views\", \"views_next_day\", \"view_growth\", \"growth_rate\"]].head(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Drop rows where growth_rate is NaN (typically the last trending day of each video)\n",
    "    df_valid = df.dropna(subset=[\"growth_rate\"]).copy()\n",
    "\n",
    "    # Define high_growth label as top 25% of growth_rate\n",
    "    threshold = df_valid[\"growth_rate\"].quantile(0.75)\n",
    "    df_valid[\"high_growth\"] = (df_valid[\"growth_rate\"] >= threshold).astype(int)\n",
    "\n",
    "    print(\"High growth threshold (75th percentile):\", threshold)\n",
    "    df_valid[\"high_growth\"].value_counts()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Select feature columns for modeling\n",
    "    feature_cols = [\n",
    "        \"video_id\",\n",
    "        \"trending_date\",\n",
    "        \"publish_date\",\n",
    "        \"publish_hour\",\n",
    "        \"views\",\n",
    "        \"likes\",\n",
    "        \"dislikes\",\n",
    "        \"comment_count\",\n",
    "        \"like_view_ratio\",\n",
    "        \"comment_view_ratio\",\n",
    "        \"view_growth\",\n",
    "        \"growth_rate\",\n",
    "        \"high_growth\",\n",
    "        \"category_id\",\n",
    "    ]\n",
    "\n",
    "    features = df_valid[feature_cols].copy()\n",
    "    features.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Save processed features\n",
    "    features.to_csv(\"../data/processed/features.csv\", index=False)\n",
    "    print(\"Saved processed features to ../data/processed/features.csv\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}