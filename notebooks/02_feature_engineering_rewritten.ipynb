{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642d1f5e",
   "metadata": {},
   "source": [
    "# Feature Engineering: YouTube Trending + Google Trends\n",
    "\n",
    "This notebook builds the modeling dataset used in `03_modeling...ipynb`.\n",
    "\n",
    "**Outputs**\n",
    "- `data/processed/features.csv`\n",
    "- `data/processed/features_with_trends.csv`\n",
    "\n",
    "The pipeline is designed to be reproducible and to avoid target leakage by defining the target using *next-day* views within each `video_id` time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c660e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 160)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a6e1c4",
   "metadata": {},
   "source": [
    "## 1) Paths and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust these paths if your folder structure differs.\n",
    "RAW_DIR = Path(\"data/raw\")\n",
    "PROCESSED_DIR = Path(\"data/processed\")\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "YOUTUBE_CSV = RAW_DIR / \"USvideos.csv\"\n",
    "TRENDS_CSV  = RAW_DIR / \"google_trends_category.csv\"  # created by 00_fetch_google_trends_final.ipynb\n",
    "\n",
    "FEATURES_OUT = PROCESSED_DIR / \"features.csv\"\n",
    "FEATURES_TRENDS_OUT = PROCESSED_DIR / \"features_with_trends.csv\"\n",
    "\n",
    "assert YOUTUBE_CSV.exists(), f\"Missing file: {YOUTUBE_CSV}. Please place USvideos.csv under data/raw/.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a22ba94",
   "metadata": {},
   "source": [
    "## 2) Load and clean YouTube trending data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2c6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(YOUTUBE_CSV)\n",
    "\n",
    "# --- Parse trending_date (format like '17.14.11' meaning YY.DD.MM in this dataset)\n",
    "def fix_trending_date(x: str) -> str:\n",
    "    # Expect YY.DD.MM\n",
    "    yy, dd, mm = x.split(\".\")\n",
    "    return f\"20{yy}-{mm}-{dd}\"\n",
    "\n",
    "df[\"trending_date\"] = pd.to_datetime(df[\"trending_date\"].astype(str).apply(fix_trending_date), errors=\"coerce\")\n",
    "\n",
    "# --- Parse publish_time -> publish_date and publish_hour\n",
    "# publish_time example: '2017-11-13T17:13:01.000Z'\n",
    "df[\"publish_time\"] = pd.to_datetime(df[\"publish_time\"], errors=\"coerce\", utc=True)\n",
    "df[\"publish_date\"] = df[\"publish_time\"].dt.date.astype(str)\n",
    "df[\"publish_hour\"] = df[\"publish_time\"].dt.hour\n",
    "\n",
    "# Basic type cleanup\n",
    "numeric_cols = [\"views\", \"likes\", \"dislikes\", \"comment_count\", \"category_id\"]\n",
    "for c in numeric_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Keep only the columns we need for features\n",
    "base_cols = [\"video_id\", \"trending_date\", \"publish_date\", \"publish_hour\",\n",
    "             \"views\", \"likes\", \"dislikes\", \"comment_count\", \"category_id\"]\n",
    "df = df[base_cols].dropna(subset=[\"video_id\", \"trending_date\", \"views\", \"category_id\"]).copy()\n",
    "\n",
    "# Sort for time-series operations\n",
    "df = df.sort_values([\"video_id\", \"trending_date\"]).reset_index(drop=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc445163",
   "metadata": {},
   "source": [
    "## 3) Feature engineering (ratios, next-day growth, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe ratios\n",
    "df[\"like_view_ratio\"] = df[\"likes\"] / df[\"views\"].replace(0, np.nan)\n",
    "df[\"comment_view_ratio\"] = df[\"comment_count\"] / df[\"views\"].replace(0, np.nan)\n",
    "\n",
    "# Next-day views within each video_id series\n",
    "df[\"views_next_day\"] = df.groupby(\"video_id\")[\"views\"].shift(-1)\n",
    "\n",
    "# Absolute and relative growth (target is based on next-day)\n",
    "df[\"view_growth\"] = df[\"views_next_day\"] - df[\"views\"]\n",
    "df[\"growth_rate\"] = df[\"view_growth\"] / df[\"views\"].replace(0, np.nan)\n",
    "\n",
    "# Drop rows where next-day is missing (can't define target)\n",
    "df_model = df.dropna(subset=[\"views_next_day\", \"growth_rate\"]).copy()\n",
    "\n",
    "# Category-normalized high-growth label:\n",
    "# within each category, label top 25% by growth_rate\n",
    "q75 = df_model.groupby(\"category_id\")[\"growth_rate\"].transform(lambda s: s.quantile(0.75))\n",
    "df_model[\"high_growth\"] = (df_model[\"growth_rate\"] >= q75).astype(int)\n",
    "\n",
    "# Keep output columns consistent with downstream notebooks\n",
    "out_cols = [\"video_id\", \"trending_date\", \"publish_date\", \"publish_hour\",\n",
    "            \"views\", \"likes\", \"dislikes\", \"comment_count\",\n",
    "            \"like_view_ratio\", \"comment_view_ratio\",\n",
    "            \"view_growth\", \"growth_rate\", \"high_growth\", \"category_id\"]\n",
    "\n",
    "features = df_model[out_cols].copy()\n",
    "\n",
    "features.head(), features.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c3fb2d",
   "metadata": {},
   "source": [
    "## 4) Save base features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dadae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv(FEATURES_OUT, index=False)\n",
    "print(f\"Saved: {FEATURES_OUT}  shape={features.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2bb01",
   "metadata": {},
   "source": [
    "## 5) Load Google Trends (category-level) and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trends file expected format: date, category_id, keyword, trend_score\n",
    "assert TRENDS_CSV.exists(), f\"Missing file: {TRENDS_CSV}. Run 00_fetch_google_trends_final.ipynb first.\"\n",
    "\n",
    "tr = pd.read_csv(TRENDS_CSV)\n",
    "tr[\"date\"] = pd.to_datetime(tr[\"date\"], errors=\"coerce\")\n",
    "tr[\"category_id\"] = pd.to_numeric(tr[\"category_id\"], errors=\"coerce\")\n",
    "tr[\"trend_score\"] = pd.to_numeric(tr[\"trend_score\"], errors=\"coerce\")\n",
    "\n",
    "# Merge on (trending_date, category_id)\n",
    "tr = tr.rename(columns={\"date\": \"trending_date\"})[[\"trending_date\", \"category_id\", \"trend_score\"]].dropna(subset=[\"trending_date\", \"category_id\"])\n",
    "tr = tr.sort_values([\"category_id\", \"trending_date\"]).reset_index(drop=True)\n",
    "\n",
    "features_tr = features.merge(tr, on=[\"trending_date\", \"category_id\"], how=\"left\")\n",
    "\n",
    "# Rolling means per category (handles missing dates by sorting within category)\n",
    "features_tr = features_tr.sort_values([\"category_id\", \"trending_date\"]).reset_index(drop=True)\n",
    "features_tr[\"trend_score_3d_mean\"] = (\n",
    "    features_tr.groupby(\"category_id\")[\"trend_score\"]\n",
    "    .transform(lambda s: s.rolling(window=3, min_periods=1).mean())\n",
    ")\n",
    "features_tr[\"trend_score_7d_mean\"] = (\n",
    "    features_tr.groupby(\"category_id\")[\"trend_score\"]\n",
    "    .transform(lambda s: s.rolling(window=7, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "features_tr.head(), features_tr.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b3d0c",
   "metadata": {},
   "source": [
    "## 6) Save features with trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tr.to_csv(FEATURES_TRENDS_OUT, index=False)\n",
    "print(f\"Saved: {FEATURES_TRENDS_OUT}  shape={features_tr.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc8e356",
   "metadata": {},
   "source": [
    "## 7) Statistical hypothesis test\n",
    "\n",
    "**Question:** Do Google Trends scores differ between high-growth and low-growth videos?\n",
    "\n",
    "- **H0:** No difference in Trends scores between the two groups.\n",
    "- **H1:** Trends scores differ between the groups.\n",
    "\n",
    "We use Mann–Whitney U (non-parametric) since the distributions are typically non-normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_high = features_tr.loc[features_tr[\"high_growth\"] == 1, \"trend_score_7d_mean\"].dropna()\n",
    "x_low  = features_tr.loc[features_tr[\"high_growth\"] == 0, \"trend_score_7d_mean\"].dropna()\n",
    "\n",
    "stat, p_value = mannwhitneyu(x_high, x_low, alternative=\"two-sided\")\n",
    "\n",
    "print(f\"n_high={len(x_high)}, n_low={len(x_low)}\")\n",
    "print(f\"Mann–Whitney U statistic: {stat:.2f}\")\n",
    "print(f\"p-value: {p_value:.6g}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Decision: Reject H0 (statistically significant difference).\")\n",
    "else:\n",
    "    print(\"Decision: Fail to reject H0 (no statistically significant difference detected).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff76846",
   "metadata": {},
   "source": [
    "## 8) Quick sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2490a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check label balance\n",
    "print(\"High-growth rate:\", features_tr[\"high_growth\"].mean())\n",
    "\n",
    "# Missingness of trend scores\n",
    "print(\"Missing trend_score:\", features_tr[\"trend_score\"].isna().mean())\n",
    "\n",
    "# Basic descriptive stats\n",
    "features_tr[[\"growth_rate\", \"trend_score\", \"trend_score_3d_mean\", \"trend_score_7d_mean\"]].describe().T\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
